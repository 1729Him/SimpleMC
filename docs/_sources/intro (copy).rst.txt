==================
Introduction
==================

Requirements
-------------

This code runs both in Python 2x and 3x. However, we highly recommend Python 3x.

You need the following scientific modules:

.. code-block:: bash
   
   sudo pip install numpy matplotlib scipy dynesty emcee


In addition, MCEvidence is necessary to estimate the bayesian evidence in the Metropolis-Hastings sampler:

.. code-block:: bash
   
   pip install git+https://github.com/yabebalFantaye/MCEvidence

For use Artificial Neural Networks with multinest and ellipsoidal sampling (as in pyBAMBI), you need to install:

.. code-block:: bash
   
   pip install tensorflow keras

For use genetic algorithms in order to maximize the Likelihood function:

.. code-block:: bash
   
   pip install deap


If you want to use the full options to plot:

.. code-block:: bash
   
   pip install corner getdist

.. note:: All in one copy-paste line: 

   .. code-block:: bash
   
      pip install numpy matplotlib scipy tensorflow keras dynesty corner getdist deap git+https://github.com/yabebalFantaye/MCEvidence



Quick Start
------------

In this section we show a basic use of SimpleMC. 

1) First you need to create an *ini file* as follows:

.. code-block::

        [custom]
        # custom -> for all analyzers : samplers and optimizers
        chainsdir = chains

        ;set model
        ;model options: LCDM, LCDMasslessnu, nuLCDM, NeffLCDM, noradLCDM, nuoLCDM,
        ;nuwLCDM, oLCDM, wCDM, waCDM, owCDM, owaCDM, JordiCDM, WeirdCDM, TLight, StepCDM,
        ;Spline, PolyCDM, fPolyCDM, Decay, Decay01, Decay05, EarlyDE, EarlyDE_rd_DE, SlowRDE, sline
        model = owaCDM

        ;prefact options : [pre, phy]
        prefact = phy

        ;set datasets used. Ex: UnionSN+BBAO+Planck
        ;data options: HD, BBAO, GBAO, GBAO_no6dF, CMASS, LBAO, LaBAO,
        ;LxBAO, MGS, Planck, WMAP, PlRd, WRd, PlDa, PlRdx10, CMBW, SN, SNx10, UnionSN,
        ;RiessH0, 6dFGS, dline
        datasets = BBAO+HD+UnionSN+Planck
        ;sampler can be {mcmc, nested, emcee}
        ;or analyzers {MaxLikeAnalyzer, genetic}
        ;
        ;mcmc -> metropolis-hastings
        ;nested
        ;engine can be {nestle, dynesty}
        ;nestedType can be
            ;none -> Prior mass without bounds
            ;single -> Ellipsoidal nested sampling
            ;multi -> multinest
            ;balls ->  balls centered on each live point
            ;cube -> cubes centered on each live point
        ;emcee
        ;MaxLikeAnalyzer -> Maximum Likelihood Analyzer
        ;genetic
        sampler = genetic
        [mcmc]
        nsamp   = 4000
        skip    = 100
        temp    = 2

        ;if single cpu, otherwise use mpi -np #
        chainno = 1

        ;add derived parameters (True/False) ,
        ;i.e. Omega_Lambda, H0, Age of the Universe
        addderived = False


        [nested]
        ;engine can be nestle or dynesty
        engine = dynesty

        ;dynamic option is only for dynesty engine
        ;dynamic and neuralNetwork can be yes/no
        dynamic = no
        neuralNetwork = no

        ;type: for dynesty -> {'single','multi', 'balls', 'cubes'}
        ;type for nestle -> {'single', 'multi'}
        nestedType = multi

        ;it is recommended around nlivepoints=50*ndim, recommended 1024
        nlivepoints = 500


        ;recommended 0.5
        accuracy = 0.01

        ;u for flat(uniform) or g for gaussian prior
        priortype = u

        ;nproc = mp.cpu_count()//2 by default, you can set with another positive integer
        nproc = 0

        ;if neuralNetwork = yes, then you can set:

        [neural]
        split = 0.8

        ;numNeurons of hidden layer
        numNeurons = 50

        [emcee]
        walkers = 200
        burnin = 0
        samples = 10000
        nproc = 4

        [MaxLikeAnalyzer]
        ;compute errror from Hessian matrix
        ;Yes/No
        withErrors = No

        ;[DerivedParameters]
        ;add Derived Parameters to chains
        ;genetic parameters

        [genetic]
        n_individuals = 10
        n_generations = 500
        ;selection_method = {tournament, ruleta, rank}
        selection_method = tournament
        ;mutation probability
        mut_prob = 0.4


.. note::

   Considerations:
  
   * *prefact* and *nsamp* are only for Metropolis-Hastings.

   * *nlivepoints* and *accuracy* are only for nested sampling.

   * *sampler* options are:
   
      * mcmc : Metropolis-Hastings.
      * nested : Nested Sampling

   * *sampler* can be one *optimizer* of the following:
      
      * MaxLikeAnalyzer : from scipy.optimize.minimize
      * genetic : a Simple Genetic Algorithm
      

   * *skip* is burnin. 
  
   * For *priortype* u is uniform prior and g gaussian prior. At this time, only nested sampling accept both of them.
   
   * *chainsdir* is the directory where the chains in a text file and the plots will be saved.

2) Then in *driver.py*, please put the path of the *ini file*:

.. code-block:: python
   
   from DriverMC import DriverMC
   
   fileConfig = "/home/isidro/SuperMC_/baseConfig.ini"
   D = DriverMC(fileConfig)



3) For last, you can run in the *SuperMC* directory:

.. code-block:: bash
   
   $ python3 Run/driver.py

You can see your outputs in the *chains* directory.

* See the `plots <plotters.html>`_ .


General structure
------------------

.. figure:: /img/simplemc.png







